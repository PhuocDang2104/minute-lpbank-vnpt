# Copy this file to infra/.env.prod on the VM and fill real values.
# Do not commit infra/.env.prod.

# Use URL-safe chars for this password (letters/numbers/_-), because it is embedded into DATABASE_URL.
POSTGRES_PASSWORD=CHANGE_ME_STRONG_PASSWORD
SECRET_KEY=CHANGE_ME_RANDOM_SECRET_MIN_32_CHARS

# AI providers
GEMINI_API_KEY=
# Gemini model names you can set in this repo:
# - gemini-2.5-flash-lite
# - gemini-2.5-flash
# - gemini-2.0-flash
GEMINI_MODEL=gemini-2.5-flash-lite
GEMINI_VISION_MODEL=gemini-2.5-flash-lite
# Optional dedicated vision key (ASR frame captioning). Leave blank to reuse GEMINI_API_KEY logic.
GEMINI_VISION_API_KEY=

# Groq model can be any model available in your Groq account.
# Example defaults in repo:
# - meta-llama/llama-4-scout-17b-16e-instruct
GROQ_API_KEY=
LLM_GROQ_CHAT_MODEL=meta-llama/llama-4-scout-17b-16e-instruct
LLM_GROQ_VISION_MODEL=meta-llama/llama-4-scout-17b-16e-instruct

# Backward-compatible aliases (keep same value as chat model if used by old code)
LLM_GROQ_MODEL=meta-llama/llama-4-scout-17b-16e-instruct
GROQ_MODEL=meta-llama/llama-4-scout-17b-16e-instruct

# ASR visual caption provider/model
LLM_VISION_PROVIDER=gemini
LLM_VISION_MODEL=gemini-2.5-flash-lite
LLM_VISION_API_KEY=

# Backend runtime
ASR_LANGUAGE=vi
REALTIME_AV_RECORD_MS=10000
LLM_OUTPUT_LANGUAGE=vi
CORS_ORIGINS=https://your-project.vercel.app,https://your-frontend-domain.com

# ASR image/runtime tuning
WHISPER_THREADS=2
WHISPER_MODEL_URL=https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin
WHISPER_MODEL_FILE=ggml-base.bin
WHISPER_MODEL=/models/ggml-base.bin
WHISPER_LANGUAGE=vi

# S3-compatible object storage (works for Supabase/SmartCloud/MinIO...)
# Important: use the S3 service endpoint (not necessarily bucket URL).
SUPABASE_S3_ENDPOINT=https://s3hn.smartcloud.vn
SUPABASE_S3_REGION=hn
SUPABASE_S3_BUCKET=minute-object-storage
SUPABASE_S3_ACCESS_KEY=
SUPABASE_S3_SECRET_KEY=
